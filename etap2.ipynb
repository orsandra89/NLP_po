{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-30T16:32:18.861303Z",
     "start_time": "2025-03-30T16:32:05.547216Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import nltk"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T16:37:04.588419Z",
     "start_time": "2025-03-30T16:37:04.373555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('popular')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ],
   "id": "5b7490c224c50f6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\serhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "aee9dfed7b5e3739",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:32:55.867123Z",
     "start_time": "2025-03-30T16:37:07.339746Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# === Function: count syllables in a word (approximation) ===\n",
    "def count_syllables(word):\n",
    "    word = word.lower()\n",
    "    return len(re.findall(r'[aeiouy]+', word))\n",
    "\n",
    "# === Function: analyze poetic structure ===\n",
    "def analyze_poem(text):\n",
    "    lines = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    num_lines = len(lines)\n",
    "    line_lengths = [len(line.split()) for line in lines]\n",
    "    syllables_per_line = [sum(count_syllables(w) for w in line.split()) for line in lines]\n",
    "\n",
    "    # Detect anaphora: repeated first word in consecutive lines\n",
    "    starters = [line.split()[0] for line in lines if len(line.split()) > 0]\n",
    "    anaphora_count = sum(1 for i in range(1, len(starters)) if starters[i] == starters[i-1])\n",
    "\n",
    "    # POS tagging for entire text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    pos_counts = dict(Counter(tag for word, tag in pos_tags))\n",
    "\n",
    "    return {\n",
    "        \"num_lines\": num_lines,\n",
    "        \"avg_line_length\": sum(line_lengths) / num_lines if num_lines else 0,\n",
    "        \"avg_syllables_per_line\": sum(syllables_per_line) / num_lines if num_lines else 0,\n",
    "        \"anaphora_count\": anaphora_count,\n",
    "        \"pos_counts\": pos_counts\n",
    "    }\n",
    "\n",
    "# === Analyze all poems in directory ===\n",
    "books_path = Path(\"poetry_books\")\n",
    "results = []\n",
    "\n",
    "for file_path in books_path.glob(\"*.txt\"):\n",
    "    with open(file_path, encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    analysis = analyze_poem(text)\n",
    "    flat_result = {\n",
    "        \"filename\": file_path.name,\n",
    "        \"num_lines\": analysis[\"num_lines\"],\n",
    "        \"avg_line_length\": analysis[\"avg_line_length\"],\n",
    "        \"avg_syllables_per_line\": analysis[\"avg_syllables_per_line\"],\n",
    "        \"anaphora_count\": analysis[\"anaphora_count\"],\n",
    "    }\n",
    "    # Flatten POS counts\n",
    "    for tag, count in analysis[\"pos_counts\"].items():\n",
    "        flat_result[f\"pos_{tag}\"] = count\n",
    "    results.append(flat_result)\n",
    "\n",
    "# === Save results to CSV ===\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"poetry_analysis_results.csv\", index=False)\n",
    "print(\"✅ Analysis complete. Results saved to poetry_analysis_results.csv\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Analysis complete. Results saved to poetry_analysis_results.csv\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "591f7fae30f61fef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
